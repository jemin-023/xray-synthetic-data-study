{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":290766524,"sourceType":"kernelVersion"}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q timm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.cuda.amp import autocast, GradScaler \nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom torch.optim.swa_utils import AveragedModel \nfrom tqdm.notebook import tqdm\nimport timm\nimport timm.utils # For ModelEmaV2\nimport pandas as pd\nimport numpy as np\nimport zipfile\nimport io\nfrom PIL import Image\nimport os\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using {device} with timm version {timm.__version__}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-09T16:43:19.394653Z","iopub.execute_input":"2026-01-09T16:43:19.395204Z","iopub.status.idle":"2026-01-09T16:43:27.023758Z","shell.execute_reply.started":"2026-01-09T16:43:19.395171Z","shell.execute_reply":"2026-01-09T16:43:27.022948Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Using cuda with timm version 1.0.20\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"MODEL_NAME = 'eva02_base_patch14_448.mim_in22k_ft_in1k' # High performance EVA-02\nIMG_SIZE = 448\nBATCH_SIZE = 16  # Small batch size due to huge 448px resolution\nGRAD_ACCUM = 4  # Gradient Accumulation to simulate Batch Size = 32\nEPOCHS = 6\n\n# 1. Custom Loss: Focal + BCE (Binary Cross Entropy)\nclass FocalLossBCE(nn.Module):\n    def __init__(self, alpha=0.25, gamma=2):\n        super().__init__()\n        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, pred, target):\n        bce_loss = self.bce(pred, target)\n        probas = torch.sigmoid(pred)\n        pt = torch.where(target == 1, probas, 1 - probas)\n        # Focal term: (1 - pt)^gamma\n        focal_loss = self.alpha * (1 - pt).pow(self.gamma) * bce_loss\n        return focal_loss.mean()\n\n# 2. Build Model & LLRD Optimizer\ndef build_model_optimizer():\n    # Load EVA-02 Model\n    print(f\"Loading {MODEL_NAME}...\")\n    model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=5)\n    model = model.to(device)\n    \n    # Layer-wise Learning Rate Decay (LLRD)\n    # We assign lower LR to early layers (backbone) and higher LR to the head\n    param_groups = [\n        {'params': model.patch_embed.parameters(), 'lr': 1e-5}, # Early layers: Low LR\n        {'params': model.blocks.parameters(), 'lr': 5e-5},      # Middle layers: Med LR\n        {'params': model.head.parameters(), 'lr': 3e-4}         # Head: High LR\n    ]\n    \n    optimizer = optim.AdamW(param_groups, weight_decay=0.05)\n    \n    # Exponential Moving Average (EMA) setup\n    # Keeps a smoother copy of the model to stabilize training\n    model_ema = timm.utils.ModelEmaV2(model, decay=0.999)\n    \n    return model, optimizer, model_ema\n\n# 3. Strong Augmentations (Geometric + Photometric)\ntrain_transforms = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(15),\n    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2)), # Geometric\n    transforms.ColorJitter(brightness=0.2, contrast=0.2), # Photometric\n    transforms.ToTensor(),\n    transforms.Normalize([0.481, 0.457, 0.408], [0.268, 0.261, 0.275]) # CLIP/EVA Stats\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.481, 0.457, 0.408], [0.268, 0.261, 0.275])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T16:43:27.027540Z","iopub.execute_input":"2026-01-09T16:43:27.027787Z","iopub.status.idle":"2026-01-09T16:43:27.037532Z","shell.execute_reply.started":"2026-01-09T16:43:27.027761Z","shell.execute_reply":"2026-01-09T16:43:27.036908Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class ZipDataset(Dataset):\n    def __init__(self, zip_path, csv_df, transform=None):\n        self.zip_path = zip_path\n        self.labels = csv_df\n        self.transform = transform\n        # Create map: 'Lung Opacity' -> 0, 'Cardiomegaly' -> 1, etc.\n        self.cls_map = {name: i for i, name in enumerate(sorted(csv_df['label'].unique()))}\n        self.num_classes = len(self.cls_map)\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        row = self.labels.iloc[idx]\n        img_name = str(row['Image_name'])\n        \n        # Read directly from zip\n        with zipfile.ZipFile(self.zip_path, 'r') as zf:\n            with zf.open(img_name) as f:\n                image = Image.open(io.BytesIO(f.read())).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n            \n        return image, self.cls_map[row['label']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T16:43:27.039229Z","iopub.execute_input":"2026-01-09T16:43:27.039843Z","iopub.status.idle":"2026-01-09T16:43:27.054753Z","shell.execute_reply.started":"2026-01-09T16:43:27.039819Z","shell.execute_reply":"2026-01-09T16:43:27.054016Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Re-initialize Dataset (Using ZipDataset)\nZIP_PATH = '/kaggle/input/train-val-test-split/train_val_data.zip'\nCSV_PATH = '/kaggle/input/train-val-test-split/train_val.csv'\n\n# Load metadata & recreate label column\ndf = pd.read_csv(CSV_PATH)\npathology_cols = ['Pneumothorax', 'Cardiomegaly', 'Lung Opacity', 'Pleural Effusion', 'Support Devices']\ndf['label'] = df[pathology_cols].idxmax(axis=1)\n\n# Split\nfrom sklearn.model_selection import train_test_split\ntrain_df, val_df = train_test_split(df, test_size=0.15, stratify=df['label'], random_state=42)\n\n# Loaders\ntrain_ds = ZipDataset(ZIP_PATH, train_df, transform=train_transforms)\nval_ds = ZipDataset(ZIP_PATH, val_df, transform=val_transforms)\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n# We use one-hot encoding for BCE Loss\ntrain_ds.num_classes = 5\n\n# Initialize Everything\nmodel, optimizer, model_ema = build_model_optimizer()\ncriterion = FocalLossBCE()\nscaler = GradScaler() # For Mixed Precision\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n\nprint(f\"Starting EVA-X Training for {EPOCHS} Epochs...\")\n\nfor epoch in range(EPOCHS):\n    model.train()\n    optimizer.zero_grad()\n    train_loss = 0\n    \n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n    for step, (images, labels) in enumerate(pbar):\n        images, labels = images.to(device), labels.to(device)\n        \n        # Convert integer labels to One-Hot for BCE\n        labels_one_hot = torch.nn.functional.one_hot(labels, num_classes=5).float()\n        \n        # 1. Mixed Precision Forward Pass\n        with autocast():\n            outputs = model(images)\n            loss = criterion(outputs, labels_one_hot) / GRAD_ACCUM\n            \n        # 2. Backward & Scaler Step\n        scaler.scale(loss).backward()\n        \n        # Gradient Accumulation Step\n        if (step + 1) % GRAD_ACCUM == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n            model_ema.update(model) # Update EMA model\n            \n        train_loss += loss.item() * GRAD_ACCUM\n        pbar.set_postfix({'loss': f\"{loss.item() * GRAD_ACCUM:.4f}\"})\n        \n    scheduler.step()\n    \n    # Save Checkpoint for Epoch 5 and 6\n    if epoch >= 4: # Epochs are 0-indexed, so 4 is epoch 5\n        torch.save(model_ema.module.state_dict(), f'eva_epoch_{epoch+1}.pth')\n        print(f\"Saved Checkpoint: eva_epoch_{epoch+1}.pth\")\n\nprint(\"Training Complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T16:43:27.055546Z","iopub.execute_input":"2026-01-09T16:43:27.055883Z","execution_failed":"2026-01-09T16:45:11.980Z"}},"outputs":[{"name":"stdout","text":"Loading eva02_base_patch14_448.mim_in22k_ft_in1k...\nStarting EVA-X Training for 6 Epochs...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_276/850548944.py:24: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler() # For Mixed Precision\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1/6:   0%|          | 0/563 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8af65bd626eb46ca8aa65041c523a07d"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_276/850548944.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"print(\"Averaging Checkpoints (Epoch 5 + 6)...\")\n\n# 1. Load the two checkpoints\nstate_dict_5 = torch.load('eva_epoch_5.pth', map_location=device)\nstate_dict_6 = torch.load('eva_epoch_6.pth', map_location=device)\n\n# 2. Average the weights\navg_state_dict = {}\nfor key in state_dict_5.keys():\n    # Simple mathematical average of the tensors\n    avg_state_dict[key] = (state_dict_5[key] + state_dict_6[key]) / 2.0\n\n# 3. Load into model and save final\nmodel.load_state_dict(avg_state_dict)\ntorch.save(model.state_dict(), 'eva_x_final_soup.pth')\n\nprint(\"Final Averaged Model Saved: eva_x_final_soup.pth\")","metadata":{"trusted":true,"execution":{"execution_failed":"2026-01-09T16:45:11.980Z"}},"outputs":[],"execution_count":null}]}